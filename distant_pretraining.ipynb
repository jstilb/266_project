{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0146f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import DebertaTokenizer, TFDebertaForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# These auto classes load the right type of tokenizer and model based on a model name\n",
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d96baa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, TF uses python ramdom and numpy library, so these must also be fixed\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7083eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_media_cloud_data(path, label):\n",
    "    \"\"\"Read in data downloaded from media cloud and assign a label to all rows\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df['Label_bias'] = label\n",
    "    df = df.rename({'title': 'sentence'}, axis=1)\n",
    "    return df\n",
    "\n",
    "# read in two datasets\n",
    "PATH_biased = \"data/news_headlines_usa_biased.csv\"\n",
    "PATH_neutral = \"data/news_headlines_usa_neutral.csv\"\n",
    "df_biased = read_media_cloud_data(PATH_biased, 1)\n",
    "df_neutral = read_media_cloud_data(PATH_neutral, 0)\n",
    "\n",
    "# combine them\n",
    "df_distant = pd.concat([df_biased,df_neutral], axis=0, ignore_index=1)\n",
    "df_distant = shuffle(df_distant)\n",
    "\n",
    "# train-test split\n",
    "df_distant_train, df_distant_test = train_test_split(df_distant, test_size=0.2)\n",
    "\n",
    "# test pipeline set\n",
    "df_distant, exclude = train_test_split(df_distant, test_size=0.95)\n",
    "df_distant_train, df_distant_test = train_test_split(df_distant, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05a2682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, model_name):\n",
    "    \"\"\"convert a pandas dataframe into a tensorflow dataset\"\"\"\n",
    "    df2 = df.copy(deep=False)\n",
    "    target = df2.pop('Label_bias')\n",
    "    sentence = df2.pop('sentence')\n",
    "\n",
    "    if model_name=='bert':\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    elif model_name=='roberta':\n",
    "        tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    elif model_name=='deberta':\n",
    "        tokenizer = DebertaTokenizer.from_pretrained(\"kamalkraj/deberta-base\")\n",
    "\n",
    "    train_encodings = tokenizer(\n",
    "                        sentence.tolist(),                      \n",
    "                        add_special_tokens = True, # add [CLS], [SEP]\n",
    "                        truncation = True, # cut off at max length of the text that can go to BERT\n",
    "                        padding = True, # add [PAD] tokens\n",
    "                        return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
    "              )\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(train_encodings), \n",
    "         target.tolist()))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f54f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df, test_df, model_name):\n",
    "    # pandas -> tensorflow\n",
    "    train_distant_dataset = preprocess(train_df, model_name)\n",
    "    test_distant_dataset = preprocess(test_df, model_name)\n",
    "\n",
    "    # batch and randomize\n",
    "    BUFFER_SIZE = 10000\n",
    "    BATCH_SIZE = 24\n",
    "\n",
    "    train_distant_dataset = train_distant_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    test_distant_dataset = test_distant_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True) # after 3 epochs without improvement, stop training\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "    \n",
    "    if model_name=='bert':\n",
    "        clf = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "    elif model_name=='roberta':\n",
    "        clf = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "    elif model_name == 'deberta':\n",
    "        clf = TFDebertaForSequenceClassification.from_pretrained(\"kamalkraj/deberta-base\")\n",
    "\n",
    "    clf.compile(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy') \n",
    "    history = clf.fit(train_distant_dataset, epochs=1, validation_data = test_distant_dataset, callbacks=[callback])\n",
    "    trained_layer = clf.get_layer(index=0).get_weights()\n",
    "    clf.save_weights(f'./checkpoints/{model_name}_final_checkpoint_news_headlines_USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a1870bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - 75s 276ms/step - loss: 3.0046 - accuracy: 0.3488 - val_loss: 2.9835 - val_accuracy: 0.3533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 16:10:57.838858: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 [==============================] - ETA: 0s - loss: 0.6397 - accuracy: 0.4737"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 16:12:18.057290: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "215/215 [==============================] - 80s 299ms/step - loss: 0.6397 - accuracy: 0.4737 - val_loss: 0.4937 - val_accuracy: 0.7694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 16:12:18.479220: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2022-10-28 16:12:18.831320: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n",
      "2022-10-28 16:12:18.998196: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154414080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8bb0a2661c404691a37225ac24094f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf22ef883e948908d887e94dcea3447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b04c34a7438467e8f540dfb67e49e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9c73541b0f48548a800c2cb487124a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/744 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7847b5850d4f2a8669eb079270f06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/555M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFDebertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFDebertaForSequenceClassification were not initialized from the model checkpoint at kamalkraj/deberta-base and are newly initialized: ['pooler', 'classifier', 'cls_dropout']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jstil/.local/lib/python3.10/site-packages/transformers/models/deberta/modeling_tf_deberta.py:123: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/jstil/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/ops/distributions/bernoulli.py:86: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "215/215 [==============================] - 153s 567ms/step - loss: 6.9446 - accuracy: 0.6461 - val_loss: 7.6550 - val_accuracy: 0.6545\n"
     ]
    }
   ],
   "source": [
    "models = ['bert', 'roberta', 'deberta']\n",
    "\n",
    "for model in models:\n",
    "    train_model(df_distant_train, df_distant_test, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
